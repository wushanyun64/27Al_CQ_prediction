{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.model import *\n",
    "\n",
    "model_path = \"../models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we choose random forest and XGboost as our choice of model for the prediction of <sup>27</sup>Al C<sub>Q</sub>. We use RandomizedSearchCV from scikit-learn to select the hyperparameter and perform 10-fold cross validation. The resultant model is test on a stand-alone test set consist of 1617 Al sites.\n",
    "\n",
    "4 models are trained here.\n",
    "1. Baseline model with pure structural based features.\n",
    "2. Improved model with structural+elemental features.\n",
    "3. Test model with SMOTE rebalance.\n",
    "4. XGboost model.\n",
    "\n",
    "The output models are saved in /model/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload features from data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/processed/nmr_param_and_features.csv\"\n",
    "with open(path, \"r\") as file:\n",
    "    nmr_struc_data = pd.read_csv(file)\n",
    "nmr_struc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"../data/processed/nmr_param_and_features_train.csv\"\n",
    "path_test = \"../data/processed/nmr_param_and_features_test.csv\"\n",
    "with open(path_train, \"r\") as file:\n",
    "    nmr_struc_data_train = pd.read_csv(file)\n",
    "with open(path_test, \"r\") as file:\n",
    "    nmr_struc_data_test = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = nmr_struc_data_train.loc[:, \"fbl_average\":]\n",
    "y_train = nmr_struc_data_train[[\"CQ\", \"is_O\"]]\n",
    "X_test = nmr_struc_data_test.loc[:, \"fbl_average\":]\n",
    "y_test = nmr_struc_data_test[[\"CQ\", \"is_O\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Baseline model with only structural based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split y and x\n",
    "# y = nmr_struc_data[[\"CQ\", \"is_O\"]]\n",
    "# x = nmr_struc_data.loc[:, \"fbl_average\":\"DI\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)\n",
    "\n",
    "# print(f\"Size of train set: {len(X_train)}\\nSize of test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split y and x\n",
    "y = nmr_struc_data_train[[\"CQ\", \"is_O\"]]\n",
    "x = nmr_struc_data_train.loc[:, \"fbl_average\":\"DI\"]\n",
    "\n",
    "X_train, _, y_train, _ = train_test_split(x, y, test_size=1, random_state=5)\n",
    "\n",
    "print(f\"Size of train set: {len(X_train)}\\nSize of test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split y and x\n",
    "y = nmr_struc_data_test[[\"CQ\", \"is_O\"]]\n",
    "x = nmr_struc_data_test.loc[:, \"fbl_average\":\"DI\"]\n",
    "\n",
    "X_test, _, y_test, _ = train_test_split(x, y, test_size=1, random_state=5)\n",
    "\n",
    "print(f\"Size of train set: {len(X_train)}\\nSize of test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the param space for randomized search\n",
    "param = {\n",
    "    \"n_estimators\": randint(low=10, high=1000),\n",
    "    \"max_depth\": randint(low=10, high=50),\n",
    "    \"min_samples_split\": randint(low=2, high=10),\n",
    "    \"min_samples_leaf\": randint(low=1, high=8),\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "grid = model_train(X_train, y_train, \"randomforest\", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the model's performance\n",
    "grid_performance(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model's performance over the test set\n",
    "grid_test(X_test, y_test, grid, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, model_path + \"struc.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Improved model with structural+elemental features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split y and x\n",
    "y = nmr_struc_data[[\"CQ\", \"is_O\"]]\n",
    "x = nmr_struc_data.loc[:, \"fbl_average\":]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)\n",
    "\n",
    "print(f\"Size of train set: {len(X_train)}\\nSize of test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the param space for randomized search\n",
    "param = {\n",
    "    \"n_estimators\": randint(low=10, high=1000),\n",
    "    \"max_depth\": randint(low=10, high=50),\n",
    "    \"min_samples_split\": randint(low=2, high=10),\n",
    "    \"min_samples_leaf\": randint(low=1, high=8),\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "grid = model_train(X_train, y_train, \"randomforest\", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the model's performance\n",
    "grid_performance(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model's performance over the test set\n",
    "grid_test(X_test, y_test, grid, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, model_path + \"struc+ele.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Test model with SMOTE rebalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split y and x\n",
    "y = nmr_struc_data[[\"CQ\", \"is_O\"]]\n",
    "x = nmr_struc_data.loc[:, \"fbl_average\":]\n",
    "# x = data_nocollinear\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)\n",
    "\n",
    "print(f\"Size of train set: {len(X_train)}\\nSize of test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the dataset using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "train = pd.concat([X_train, y_train[\"CQ\"]], axis=1)\n",
    "label = y_train[\"is_O\"]\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.75)\n",
    "under = RandomUnderSampler(sampling_strategy=1.0)\n",
    "steps = [(\"o\", over), (\"u\", under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "train, label = pipeline.fit_resample(train, label)\n",
    "y_train = pd.concat([train[\"CQ\"], label], axis=1)\n",
    "X_train = train.drop(columns=[\"CQ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the data is balanced\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=pd.concat([X_train, y_train], axis=1), x=\"CQ\", hue=\"is_O\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the param space for randomized search\n",
    "param = {\n",
    "    \"n_estimators\": randint(low=10, high=1000),\n",
    "    \"max_depth\": randint(low=10, high=50),\n",
    "    \"min_samples_split\": randint(low=2, high=10),\n",
    "    \"min_samples_leaf\": randint(low=1, high=8),\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "grid = model_train(X_train, y_train, \"randomforest\", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the model's performance\n",
    "grid_performance(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model's performance over the test set\n",
    "grid_test(X_test, y_test, grid, plot=True, is_O=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, model_path + \"smote.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV. XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split y and x\n",
    "y = nmr_struc_data[[\"CQ\", \"is_O\"]]\n",
    "x = nmr_struc_data.loc[:, \"fbl_average\":]\n",
    "# x = data_nocollinear\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)\n",
    "\n",
    "print(f\"Size of train set: {len(X_train)}\\nSize of test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the param space for randomized search\n",
    "param = {\n",
    "    \"learning_rate\": uniform(0, 1),\n",
    "    \"max_depth\": randint(3, 50),\n",
    "    \"min_child_weight\": randint(1, 10),\n",
    "    \"eta\": uniform(0.01, 0.2),\n",
    "    \"gamma\": uniform(0, 1),\n",
    "    \"reg_alpha\": [1e-5, 1e-2, 0.1, 1, 100],\n",
    "    \"subsample\": uniform(0, 1),\n",
    "    \"colsample_bytree\": uniform(0, 1),\n",
    "}\n",
    "\n",
    "grid = model_train(X_train, y_train, \"XGboost\", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the model's performance\n",
    "grid_performance(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model's performance over the test set\n",
    "grid_test(X_test, y_test, grid, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(grid.best_estimator_, model_path + \"xgboost.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('27al_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a100d861a3d6438a0153a54f755c32ecbafe1a787960322fb78fe4fcf72b617a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
