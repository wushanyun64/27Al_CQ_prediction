{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27Al CQ prediction with SOAP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pymatgen.core.structure import Structure as ST\n",
    "from src.soap_utilities import getXY, get_species\n",
    "\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing and generate soap feature\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only show warnings once\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read processed data and continue\n",
    "with open(\"./data/processed_data_0.5.json\", \"r\") as file:\n",
    "    data_reload = json.load(file)\n",
    "for data in data_reload:\n",
    "    data[\"structure\"] = ST.from_dict(data[\"structure\"])\n",
    "print(\"length of data set is:\", len(data_reload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atom Species\n",
    "species_list, compositions = get_species(data_reload)\n",
    "print(\"num of species in the data set:\", len(species_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, loc = getXY(data_reload, species_list)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache X and y\n",
    "sparse.save_npz(\"./data/soap_X.npz\", X)\n",
    "y[[\"nmr\"]].to_csv(\"./data/soap_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA of X\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload X\n",
    "X = sparse.load_npz(\"./data/soap_X.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "N = 35\n",
    "pca = TruncatedSVD(n_components=N, n_iter=8, random_state=20)\n",
    "X_pca_fit = pca.fit(X)\n",
    "X_pca = X_pca_fit.transform(X)\n",
    "\n",
    "print(f\"PCA covers {sum(X_pca_fit.explained_variance_ratio_)}% of variance\")\n",
    "print(f\"PCA done! New shape {X_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache X_pca\n",
    "np.savetxt(\"./data/soap_X_pca.csv\", X_pca, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test of random forest model\n",
    "----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X_pca and y\n",
    "X_pca = np.loadtxt(\"./data/soap_X_pca.csv\", delimiter=\",\")\n",
    "y = pd.read_csv(\"./data/soap_y.csv\")[[\"nmr\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get absolute value of CQ\n",
    "y[\"nmr\"] = abs(y[\"nmr\"])\n",
    "\n",
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.2, random_state=20\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Grid Search for Algorithm Tuning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import math\n",
    "\n",
    "# create and fit a kernel ridge regression model\n",
    "model = RandomForestRegressor(random_state=10, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "param = {\n",
    "    \"n_estimators\": randint(low=100, high=500),\n",
    "    \"max_depth\": randint(low=10, high=100),\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param,\n",
    "    n_iter=10,\n",
    "    scoring=[\"neg_mean_absolute_error\", \"neg_mean_squared_error\", \"r2\"],\n",
    "    refit=\"r2\",\n",
    "    cv=5,\n",
    "    n_jobs=8,\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train[\"nmr\"])\n",
    "\n",
    "# summarize the results of the grid search\n",
    "train_r2 = np.sort(grid.cv_results_[\"mean_test_r2\"])[-1]\n",
    "train_RMSE = math.sqrt(\n",
    "    -np.sort(grid.cv_results_[\"mean_test_neg_mean_squared_error\"])[-1]\n",
    ")\n",
    "train_MAE = -np.sort(grid.cv_results_[\"mean_test_neg_mean_absolute_error\"])[-1]\n",
    "\n",
    "print(\n",
    "    \"training score: R2 = {}, RMSE = {}, MAE = {}\".format(\n",
    "        train_r2, train_RMSE, train_MAE\n",
    "    )\n",
    ")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Predict test set\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from src.Utility import reg_plot\n",
    "\n",
    "sns.set()\n",
    "\n",
    "y_rf = grid.predict(X_test)\n",
    "\n",
    "test_r2 = r2_score(y_test[\"nmr\"], y_rf)\n",
    "test_RMSE = math.sqrt(mean_squared_error(y_test[\"nmr\"], y_rf))\n",
    "test_MAE = mean_absolute_error(y_test[\"nmr\"], y_rf)\n",
    "\n",
    "print(\"test scores: R2 = {}, RMSE = {}, MAE = {}\".format(test_r2, test_RMSE, test_MAE))\n",
    "\n",
    "\n",
    "# plot\n",
    "reg_plot(\n",
    "    y_test[\"nmr\"], y_rf, \"VASP calculated CQ(MHz)\", \"Random forest predicted CQ (MHz)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build learn curve base on sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload X_pca and y\n",
    "X_pca = pd.read_csv(\"./data/soap_X_pca.csv\", header=None)\n",
    "y = pd.read_csv(\"./data/soap_y.csv\")[[\"nmr\"]]\n",
    "y[\"nmr\"] = abs(y[\"nmr\"])\n",
    "y.rename(columns={\"nmr\": \"CQ\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a series of smaller data sets (10%-100%)\n",
    "whole_dataset = pd.concat([y, X_pca], axis=1)\n",
    "\n",
    "small_sets = []\n",
    "for p in range(1, 11):\n",
    "    small_sets.append(whole_dataset.sample(frac=p / 10, random_state=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build learning curve\n",
    "from src.Utility import learning_curve_samplesize\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    random_state=10,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    max_depth=50,\n",
    "    n_estimators=500,\n",
    "    max_features=\"sqrt\",\n",
    ")\n",
    "feature_names = list(range(35))\n",
    "learning_curve_dict = learning_curve_samplesize(model, small_sets, feature_names)\n",
    "pd.DataFrame(learning_curve_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "pd.DataFrame(learning_curve_dict).to_csv(\"./data/soap_learning_curve_samplesize.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('27al_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a100d861a3d6438a0153a54f755c32ecbafe1a787960322fb78fe4fcf72b617a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
